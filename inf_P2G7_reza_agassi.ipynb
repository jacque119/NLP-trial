{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Ch 9 - Model Inference**"
      ],
      "metadata": {
        "id": "QKJ43DIb_NLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout, GlobalAveragePooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoH71D4t_j2R",
        "outputId": "7fca0528-1ed1-4e90-c861-5034c9314340"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-9E8xty-Zh6",
        "outputId": "4e6d8816-9e34-47e6-936e-aa7573fe01f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "model = load_model('best_model.h5')  # or 'best_model.keras' if you used that format\n",
        "\n",
        "# Load tokenizer\n",
        "with open('tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\bbr\\b\", \"\", text)\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n"
      ],
      "metadata": {
        "id": "dl_BOYa7_c4b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text\n",
        "sample_review = \"I really enjoyed the movie. The plot was strong and the acting was superb!\"\n",
        "\n",
        "# Clean, tokenize, and pad\n",
        "cleaned = clean_text(sample_review)\n",
        "sequence = tokenizer.texts_to_sequences([cleaned])\n",
        "padded = pad_sequences(sequence, maxlen=200, padding='post', truncating='post')\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(padded)\n",
        "sentiment = \"Positive\" if prediction[0][0] >= 0.5 else \"Negative\"\n",
        "print(f\"Predicted Sentiment: {sentiment} (Confidence: {prediction[0][0]:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBnQo8Se_o3E",
        "outputId": "0818199e-1c30-473e-c10a-4470ae2bf8b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
            "Predicted Sentiment: Positive (Confidence: 0.9694)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference Result\n",
        "\n",
        "We performed a real-time inference using our trained sentiment classification model. The input was a manually written movie review:\n",
        "\n",
        "> \"**I really enjoyed the movie. The plot was strong and the acting was superb!**\"\n",
        "\n",
        "The review underwent the same preprocessing steps as the training data — including lowercasing, HTML tag and special character removal, and stopword filtering.\n",
        "\n",
        "After tokenization and padding, the model predicted the sentiment as:\n",
        "\n",
        "- **Predicted Sentiment:** **Positive**  \n",
        "- **Confidence Score:** **0.9694**\n",
        "\n",
        "This high confidence score indicates the model's strong certainty that the review expresses positive sentiment, showcasing its ability to generalize well to unseen data.\n"
      ],
      "metadata": {
        "id": "IxKBRuV2ANep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model sucessfully identified positive sentiment next let's try with negative one!"
      ],
      "metadata": {
        "id": "eIrLwxH1Al2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text\n",
        "sample_review = \"The movie was painfully slow and the plot made no sense at all.\"\n",
        "\n",
        "# Clean, tokenize, and pad\n",
        "cleaned = clean_text(sample_review)\n",
        "sequence = tokenizer.texts_to_sequences([cleaned])\n",
        "padded = pad_sequences(sequence, maxlen=200, padding='post', truncating='post')\n",
        "\n",
        "# Predict\n",
        "prediction = model.predict(padded)\n",
        "sentiment = \"Positive\" if prediction[0][0] >= 0.5 else \"Negative\"\n",
        "print(f\"Predicted Sentiment: {sentiment} (Confidence: {prediction[0][0]:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8phY5NCmAOFT",
        "outputId": "a05b8664-9529-4baa-f9e3-f96ce8b86037"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Predicted Sentiment: Positive (Confidence: 0.6287)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference Result (Misclassified Example)\n",
        "\n",
        "We tested the model using the following clearly negative statement:\n",
        "\n",
        "> *\"The movie was painfully slow and the plot made no sense at all.\"*\n",
        "\n",
        "Despite the review expressing clear dissatisfaction, the model predicted:\n",
        "\n",
        "- **Predicted Sentiment:** **Positive**\n",
        "- **Confidence Score:** **0.6287**\n",
        "\n",
        "This misclassification highlights one of the model's limitations — it may struggle with certain types of criticism that lack strong negative keywords or are expressed in more formal or indirect language. This insight could guide future model improvements, such as enhancing context understanding or fine-tuning on a more nuanced dataset.\n"
      ],
      "metadata": {
        "id": "BO6ZFvsaBHBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It fail when predicting negative sentiment this is may be caused the lack of strong negative word so the model only identify pain word as a general sentiment."
      ],
      "metadata": {
        "id": "zCn0bu-hBjg5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uP7oOGhIBHcq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}